{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Things-Learned I'm on a journey to learn all things Linux, DevOps, SysAdmin, Security, InFoSec & more. On this journey, I have found it super hard to understand things sometimes- if not all the time. The tech community has a tendency to write things in a way that assumes the reader is at a certain level, usually moderate to proficient. This repo will double as not only my notes (to reference at any time in my lifetime) but as a place for you, if you too find yourself in new territory hopefully this will help. I can only cover what I am exposed to, if there is something you would like to work on together, please let me know- I am happy and eager to learn!","title":"Introduction"},{"location":"Ansible%20Vault/","text":"Task Playbooks that had .vault_pass.sh files with permissions of 644 needed to be updated to 655. Passwords stored here would be easy to decrypt in these playbooks. Lesson learned this explanation is mediocre at best because I am taking the notes from memory rather than having typed it in parallel as I worked. Will amend this for future tasks. read the steps with caution if you ever find yourself on this page for pass assistance. Steps When working with an organizations private/public git repo, its important to understand that these repo's need to be copied locally on to your machine. The most secure format is to SSH, be sure that your rdsa key is within the organizations LDAP, these brings ease & security when trying to access private severs, machines & services. Once the repo is local on your machine, insure that you have the .git file as this will contain the information needed for you to push pull merge & commit to the organizations repo. In each playbook, I searched for the .vault_pass.sh with a ls -la command. Once found, I checked for the permissions a 644 would read as [-rw-r-r] which is not what we want. Good practice to take note of all the playbooks that have the permissions set to this. I took notes in a note pad. Make a backup of of vault_pass.sh with the following command cp vault_pass.sh bk.vault_pass.sh . This covers you in the event something goes wrong with the file you're working on, the authenticity of the original remains. Pass reads from the vault_pass.sh file, this file should be pointing to the pass path so it can decrypt and show you your passwords. It should resemble something like pass show ${XXXX_PASS_PATH}reponame/department/vault With the vault_pass.sh pointing to the correct path you now have to find all the other secret files, using the tree command at the root of the folder will allow you to see easier where the path to these files are. Once found you can run: ansible-vault rekey --new-vault-password-file .vault_pass.sh --vault-password-file bk.vault_pass.sh directory/secrets.yml After this you can run pass show to secure that the passwords have been encrypted and are able to function with the changes made.","title":"Ansible Vault"},{"location":"Clinv/","text":"Clinv What is it? Clinv was created by my good friend and could be found here . Beware, the documentation is very bare but I am working on adding content based off of my use case for no0bs. Clinv was created to asset inventory on AWS. Current Issue I need to connect clinv to my aws. But how to do that? One must first download aws cli . More information can be found here . Running aws configure will have me at a prompt in which I will use my AWS credentials for the IAM key. The IAM key can be found within your security settings of your aws account.The password only shows once - so you will want to do it that one time. If you have forgotten the password, simply create a new one and add into aws configure or amend your /.aws/config file. To connect clinv with the recently created aws cli run clinv update to update and this will show you a layout of the items you have connected to your amazon. Clinv troubleshooting: My clinv update was not working so I needed to see the error. The output said that it was with the region not connecting. I needed to check my aws configure file. To do that I typed cd .aws from there I ran ls which showed me the contents of the .aws directory, within there I saw the config file. There I opened and realized I had Region: US East (N. Virginia) us-east-1. The region needed to be: us-east-1 Once that was changed I reran clinv update and it worked! Clinv was connected to my aws.","title":"Clinv"},{"location":"Coda/","text":"","title":"Using Coda"},{"location":"Commands/","text":"Commands I've learned","title":"Commands"},{"location":"Debian%2010/","text":"Switching to Debian Network error was the first thing I noticed during the installation wizard. iwlwifi-3168-24.ucode Solution found here","title":"Debian Install"},{"location":"Docker/","text":"Docker On my journey, I learned that my organization makes use of Docker often. Here are my notes on the tool. Why use it ? Sometimes OS\u2019s and services are not compatible which leads to issues libraries , OS, & dependencies that will not work together. Docker runs components, dependencies in its own containers. Just had to build the docker configuration once. Containers are completed isolated environments, they can have their own network interfaces, etc but they all share the same OS kernel. Docker uses LXC containers. OS have two things, an OS kernel and a set of software. The OS kernel interacts with the underlying hardware. Its the software above the OS kernel that makes them different. Could have different compilers, user interface etc. Sharing the underlying kernel, what does that mean? Docker can run any flavor of OS so long as they are all based on the same kernel. Each docker container has the additional software that makes these OS's different. You will not be able to run a window based container with an Linux OS kernel. When you install Docker on windows you work Linux container on Linux virtual machine on windows. Unlike hyper visors, Docker not meant to run different OS's, dockers package and ship them anywhere any time as many times as we want. Docker installs on the OS. Containers VS Virtual Machines Utilization is used higher disk space, CPU space when you use a virtual machine. Docker allows it to boot up in seconds. Docker has less isolation as more resources are shared. You can see Docker hosted on virtual docker. Products are containerized. If you need to run multiple you could, you just need to remember to add a front load balancer. If one fails you can delete it and re-download it. ## How to Use Docker? There is a dockerhub or dockerstore. Where you can use docker run [REGISTRY PRODCUT NAME] ex: docker run ansible Container VS Image An image is a package or template, like a VM template that is used to create one or more containers that are running instances of images that are isolated and have their own enviornments & set of processes. You can create your own Docker image and push it to the docker repository. Developers & Ops In the past Developers would create the requirements and a set of instructions on how hosts must be set up, what prerequists are to be installed on the host and how the dependencies are to be configured, etc. OPs teams would hit issues as they did not develop, so working with developers to resolve. With docker the operations and developers team work together to transform the guide into a docker file with both of their requirements.The image can now run on any host, and it will work anywhere when deployed in production. Getting Started Docker has two editions, community (free docker products), Enterprise (paid products). Community is available on cloud platforms and on all major OS (Linux, Mac,Windows). If on Windows/OS you will have to run a virtual machine for Linux. Install Go here I installed using the convientient script. $ curl -fsSL https://get.docker.com -o get-docker.sh $ sudo sh get-docker.sh With the following command I am pullling an image from dockerup called whalesay sudo docker pull docker/whalesay To run this image I ran sudo docker run docker/whalesay cowsay [INPUT] (insert my hi friendu photo here) ## Docker Commands docker run runs a container from an image If the image is not found it will pull the image from Docker hub, for the first time. docker ps lists all the containers that are running some basic information about them- name, container ID, names, ports and status. Each container gets a random name and ID. docker ps -a lists all the containers including previously stopped or exited containers. docker stop [CONTAINER ID OR CONTAINER NAME] will stop the running container. docker rm [CONTAINER ID OR CONTAINER NAME] will remove the docker container compeltely. docker images lists available images and their sizes docker rmi [IMAGE NAME] removes the images, but you must stop and remove all dependent container before it can be removed. docker pull [IMAGE] only pull the image and not run the container containers are not meant to host OS's, they are designed to carry computations or run the images. A container only lives as long as the process is alive inside. docker exec [IMAGE NAME] [COMMAND] will run a command within the container. docker run -d [IMAGE NAME] will run the container detached. docker run --name [DESIRED NAME] [IMAGE] will run a container and name it your desired name docker run [IMAGE NAME] would run the latest image docker run [IMAGE NAME]:[VERSION NUMBER] this would be considered a tag and docker would know to pull an image of this version Docker containers by default do not listen to standard input. It runs in a noninteractive mode. To have input you must include the -i argument in your command, this will run docker in interactive mode. No prompts will run with the -i argument as the prompt is on the terminal. The prompt must be set by adding -it argument rather than just -i . -t stands for a psudo terminal. Every docker container gets assigned an IP by default, its internal and can only be accessed within the docker host. If you have an image running on an internal docker , users outside the internal docker cannot access. To ammend this you can use the IP of the docker host, but you have to map the port inside the docker container to a free port. *Need to review and rewrite port mapping section. docker run -p 38282:8080 kodekloud/simple-webapp:blue this command would run docker with the container host being 38282 on port 8080 with the tag blue for image simple-webapp Data is persistent in a docker container. All data is gone if you delete the container. Best practice is to map directories to the docker host. It will mount directories inside the container and stored on the external volume and remains even if you delete the docker container. docker run -v /opt/datadir:/var/lib/mysql mysql this command would mount it to the var lib and then its specified to the directory inside the container. This is important because if you delete the Docker container the information remains if mounted in another point. docker inspect [CONTAINER NAME OR ID] gives you properites on a running container. docker logs [CONTAINER ID OR NAME] shows you the logs (the content written to the standard out of the container) docker run -it this command attaches to the terminal and in interactive mode on the designated container. Enviornment Variables Found under the config line in the container.","title":"Docker"},{"location":"Gitea/","text":"Gitea I came across Gitea at my old organization. It was what the systems team used instead of Github. Gitea allows you to host on your own sever and is 100% customizable. Coming into my new organization, as I would be a systems team by myself I wanted to have something similar for my boss to track what I was doing and for me to maintain myself organized. Later I would out that my boss prefers to use Asana for tracking so this project has been put on pause; nonetheless I want it documented as it was a bit of an adventure. Starting My friend told me about Disroot which met my needs for a) anonymity b) ease of use. So I created an account here . After being verified I had my own cup of tea for Gitea- but I had to use Disroot as the middle man, for now. Custom Issue Templates In my old organization my team had a custom issue template that I really liked. With my new Gitea I realized that I had something similar but alas it was not the same. This revealed two problems: I needed to connect to Gitea to modify the files so that the web would reflect my configurations. How to connect to Gitea via my terminal? Problems Solved After doing some research & pulling from my memory bank I realized that I had to generate an SSH key, store it within the settings of my Gitea. This would come in hand when attempting to speak to the Disroot server that would then connect me to my Gitea. The next issue was actually verifying that the ssh key could speak to git and connect. You have to install git and use it in a terminal by example : cd /path/where/you/want/your/clone git clone git://user@host/path/to/git/repo.git I then went into my git-repo folder from there I saw that I had an old git so I had to remove with rm -rf .gitea so that it would clear everything out and there would not be conflict. Then I ran git clone with the SSH URL pulled from my gitea online. They were connected and I could run commands like git push , git pull etc. From there I needed to create the mkdir .gitea . When Gitea runs, it searches the configuration files for something called ISSUE_TEMPLATE if it doesn't find then it will continue to look the same as before. Once the issue template file is created you can add content from online templates. My friend shared the one he created which I used. Including it below for your own modification or starting point. --- name: \"Bug\" about: \"Maintenance of existing infrastructure\" --- name: \"Bug\" about: \"Maintenance of existing infrastructure\" labels: - \"OKR: Maintenance\" - \"Priority: High\" --- <!-- Write a meaningful description of the issue below this line. --> ## Validation Criteria <!-- Describe what do you expect to have once the task is done --> * [ ] ## Steps <!-- Describe the steps required to fulfill the validation criteria. They should be clear enough so that anyone of the team is able to follow them. --> * [ ]","title":"Gitea"},{"location":"Intro%20to%20Web%20Applications/","text":"What are web applications? Web applications are interactive applications that run on web browsers. Normally they adopt the client-server architecture to run and handle interactions. They have the website interface which is what the user see's and engages with, then there's the back end where the source code that runs on the servers live. Historic Past In web 1.0 it was static pages for everyone and appeared the same for everyone. Now Contrast to today where web pages are dynamic, improved interoperability and heavier emphasis on user experience (UX). Deeper reading found here & here Traits Web applications are platform-independent and can run on any browser on any operating system. The functions of a web application are executed remotely on the remote server (leaving the users hard drive free). This also improves version roll out, all users no matter where have access to all the applications because updates are stored on the web server. Native Operating systems are another type of web applications. IT allows to create custom experiences that go further than just the web browsers capabilities. Web Application Distribution THere are open source web applications used world wide. But there are other that are closed source and normally sent through a subscription plan. open source web applications Joomla , Wordpress . Will attempt to find more at another time. closed source web applications Wix , Shopify , DotNetNuke . Security Because a web application can is accessed by many in around the world, its essential to make sure the web application is secure. A deeper reading in web application security testing can be found here . Front end trinity vulnerabilities are: HTML CSS JavaScript Another vulnerability type is SQL injections that are typically tied to Active Directory. Common Flaws SQL Injection : allowing attackers to spoof identities, tamper with data or disclose / destroy system data. File Inclusion : allowing attackers to include a file that if modified correctly could lead to cross site scripting, denial of service and more. Unrestricted File Upload : files that have executable code into systems. Indirect Object Reference : allow an attacker to find a pattern to then extort. Web Application Layout Category Description Web Application Infrastructure the structure of required components such as a database needed for the application to run as intended. Web Application Components represents all the components that the web application might interact with. Divided into the UI/UX,Client and Server. Web Application Architecture Architecture comprises all the relationships between the various web application components. Web application infrastructure can be split into 4 main models: Client-Server One server Many Servers - One Database Many Servers - Many Databases Client-Server: the server hosts the web application and distributes it to any client that accesses it. Breakdown A client will visit a web URL, the server uses the main web application interface UI. The user will click a button or request a specific function, think adding an item to a cart, logging in, etc. The browser sends an HTTPS/HTTP request to the server which then takes that request and performs the necessary tasks. When the server has the required data it sends the results back to the client browser displaying the results in a human-readable way. One Server: Considered the riskiest design- the web application and their components including the database are hosted on a single server.If the server becomes compromised or goes down for any reason, all hosted web applications become entirely inaccessible until resolved. Many Servers - One Database: This model can allow several web applications to access a single database and to have access to the same data without syncing the data between them. The web applications can be replicated from one of the main applications (backup/primary) or they can be separate web applications that share common data. Many Servers-Many Databases: Databases hold different web application data. The web application can only access private data and only common data that is shared across web applications. It's also possible to host each web applications database on its separate database server. This method is best used for redundancy purposes. This requires the use of load balancers because it offers access control measures and proper asset segmentation. Web Application Architecture Layer Description Presentation Layer UI process components that enable communication with the application and the system. Client accesses via web browser and are returned to the server in the form of HTML,Javascript and CSS. Application Layer All web requests by the client are correctly processed. Criteria's are checked, includes authorization, privileges and data passed on to the client. Data layer Works with the application later to determine where the required data is stored and can be processed. Microservices Normally these are independent components of the web application that are typically programmed for one task only. These services can range to the following: registrations searching payments ratings reviews Microservices use what would be considered stateless, the request and response are independent. The reason for this is that the data is stored separately from its respective microservice. Microservices have easier scaling, faster development of applications , agility, reusable code & resilience. Serverless Cloud providers like Azure, AWS and GCP allow serverless architectures for paid fees. The web applications are stateless, running on computing containers like Docker. This allows for companies to have the flexibility to build and deploy applications and services without having to manage the infrastructure. Front End & Back End Front end refers to everything that the user is going to interact with on a website, this also goes hand in hand with the UX or user experience. Languages for front end are normally HTML, CSS, & Javascript. Back end of a web application drives the core web application functionalities which are executed on the back end server that then processes everything required for the web application to run correctly. Component Description Back end server hardware and OS's that host the components like Linux,Windows or containers Web server handles all the HTTP requests and connections like APache & NGINX Databases store and retrieve the web application data like MySQL MSSQL Development frameworks development frameworks are used to develop core web application, like PHP, C#,Python HTML URL Encoding, or percent-encoding. For a browser to properly display a page's contents, it has to know the charset in use. In URLs, for example, browsers can only use ASCII encoding, which only allows alphanumerical characters and certain special characters. Therefore, all other characters outside of the ASCII character-set have to be encoded within a URL. URL encoding replaces unsafe ASCII characters with a % symbol followed by two hexadecimal digits. For example, the single-quote character ''' is encoded to '%27', which can be understood by browsers as a single-quote. URLs cannot have spaces in them and will replace a space with either a + (plus sign) or %20. The World Wide Web Consortium (W3C) defines DOM as: \"The W3C Document Object Model (DOM) is a platform and language-neutral interface that allows programs and scripts to dynamically access and update the content, structure, and style of a document.\" The DOM standard is separated into 3 parts: Core DOM - the standard model for all document types XML DOM - the standard model for XML documents HTML DOM - the standard model for HTML documents CSS CSS defines the style of each HTML element or class between curly brackets {}, within which the properties are defined with their values (i.e. element { property : value; }). JavaScript JavaScript is usually used on the front end of an application to be executed within a browser. While HTML and CSS are mainly in charge of how a web page looks, JavaScript is usually used to control any functionality that the front end web page requires. JavaScript is also used to automate complex processes and perform HTTP requests to interact with the back end components and send and retrieve data, through technologies like Ajax. Sensitive Data Exposure On the client-side if attacked, they put the end-user in danger of being attacked and exploited if they do have any vulnerabilities. If a front end vulnerability is leveraged to attack admin users, it could result in unauthorized access, access to sensitive data, service disruption, and more. Sensitive Data Exposure refers to the availability of sensitive data in clear-text to the end-user. Source code is of a web page or the page source on the front of web application is the HTML source code not to be confused with the back end code that is typically only accessible on the server itself. You can view any websites page source by either right clicking and selecting page source or pressing ctrl + u . IF those options do not work you could use a web proxy like Burp suite. HTML Injection It is critical to validate and sanitize user input on both the front end and the back end of the user input. HTML Injection occur when unfiltered user input is displayed on the page. This can be either through retrieving previously submitted code, think a user comment from the back end of the database or directly displaying the unfiltered input through JavaScript on the front end. Web page defacing consists of injecting new HTML code to change the web pages appearance. Injecting a malicious link could be something like inserting the following line into the web page <a href=\"evil website\">Click Me</a> . This would direct the user to press click me which would take them else where to obtain their credentials. Cross-Site Scripting (XSS) However, XSS involves the injection of JavaScript code to perform more advanced attacks on the client-side, instead of merely injecting HTML code. There are three main types of XSS: Type Description Reflected XSS happens when user input is displayed on the page after processing (think search result/ error message) Stored XSS happens when user input is stored on the back end database and then displayed upon retrieval (think posts/comments) DOM XSS happens when user input is directly shown in the browser and is written to an HTML DOM (vulnerable username or page title) if you're able to input your payload into a web site to, for example, obtain a cookie value. That value can then be used to attempt to authenticate to the victims account. Cross-Site Request Forgery(CSRF) Utilizes front end vulnerability that is caused by unfiltered user input. It performs certain queries and API calls on a web application that the victim is currently authenticated to, allowing the attacker to perform actions as the authenticated user. Type Description Sanitization remove special characters and non-standard characters from user input before displaying or storing it Validation ensuring that submitted user niput matches the expected format, think email matching email format Web application firewall (WAF) filters, monitors and blocks HTTP traffic to and from a web service. Back End Servers A back end server is the hardware and operating system on the back end that hosts all of the applications necessary to run the web application. It's the real system running all of the processes and carrying all of the tasks that make up the entire web application. The back end server fits in the data access layer. There are 3 back end components: 1) web server 2) database 3) development frame work","title":"Introdcution"},{"location":"Markdown%20Syntax/","text":"Learning Markdown Why am I doing this? Much like my username, I am a complete no0b when it comes to all things git, linux, command line and tech in general. I've realized in my path of enlightenment there is not tons of information that starts from the bottom of the barrel. Most things I have seen start from a moderate level or they give you the steps expecting you to know certain steps...I am making this for folks that want to learn from scratch, consider this us learning together. Why should I learn markdown? In order to work on Git, your repos will most likely be made in markdown. Best practice in Git is to create a \u201cREADME.md\u201d file. This file normally tells the git user what the project is about, installation information, and much more. Markdown has two versions: rendered version (the pretty/ easy on the eyes) & the raw version (this will look like code). See the image below for what I mean about \"code\". yes i know the above image has incorrect syntax, i will show you why if you keep on reading! Markdown Preview Tools & one tip If you're not yet a seasoned professional with markdown, it\u2019s great to be able to see a preview of the work you\u2019re doing, live. Currently I am on a Mac (i know boo- but its what i have). I am using the Brackets open source tool in conjunction with the Brackets Mark Down Preview. This allows me to see what I am typing in real time. If don't get the extension you can preview it by clicking the lighting bolt icon and it will open up a chrome window for you to preview, pretty neat. Note that it only works with Chrome. Git has its own preview but its annoying to click between two tabs to see what you're doing as you type. File extension for markdown is \".md\". I will be looking into Ubuntu Options as well.For you windows users, I hate that OS so you're on your own- or write me and we can work together to find something! Markdown Syntax Titles & Subtitles If you're anything like me, you will find a cool project on Git and realize that (in some cases not all) that the publisher has made a complete mess of the page and its generally hard to read. I like things to be clean and clear. Dividing your README.md files into chapters (if you will) is a great way to do that. The hashtag # has to come first then a space then your title. No quotations \u2192 # your desired text - \u201c#\u201d creates your title (H1) - \u201c##\u201d creates your subtitle (H2) - \u201c###\u201d -\u201c######\u201d creates your other header types (H3-H6) Remember that space after the hashtag, spacing is key in markdown as I've learned. Paragraphs To write a paragraph(s), you simply have to write text underneath your title, there's no special spacing or characters needed. Depending on your markdown preview or where you're posting one thing to note is line breaks. Some places might as for a line skip to signal a line break. To break that down: if you are on line 2, and enter your text then press enter and continue the paragraph on line 3- your rendered version will not show the text spaced out, it would be one continuously line. To break that line, you have to skip a line and start, so that is 2, skip line 3, and continue your text on line 4. Your rendered version should show that desired line break. Lists If you want lists you can add those by using one of two symbols: + or - You can stack your lists by moving to the next line. If you want to indent, you put a space at the start of the line and enter either the + or -. See below for how that would look. Links & Images If you want to include links in your markdown files you enter the description within brackets \"[description here]\" then the URL between parenthesis \"( https://www.youtube.com )\". Note that there should not be space between the brackets and parentheses- it wont work if there is. Click me For images, the syntax its a little tricky to understand but bear with me. You're going to include an exclamation point followed by brackets with the words \"alt text\" then your image URL between parentheses. You can pull image URLs by clicking the image, right click and selecting view info, this is different per website, OS, etc. Will work on a break down a few later. In-line Code To use the in-line code you're going to want to use the tilde symbol, this should normally be under the esc key on your keyboard. I will let you figure that one out as homework! When you want your code to appear in a block you enter three tildes, then the code you would like, followed by three more tildes on the next line. See the example below If you want to simply make your command seen, you can wrap the command between two tildes. When I say wrap that means one at the start of the command and one at the end. Tables I read somewhere that tables are not normally supported in markdown but Git allows it, so I will show you how to do that. The easiest way is with a photo. Take note of the pipe being used between each column. Additional, see that in every line there is a space. In the second line(58) you can see that there are three dashes it has to be 3. Also notice the spacing before and after each word and pipe- this is important if you want it to work. Spicy Text If you want to add a little style to your text you can do the following Bold: wrap your word in two asterisks \"*\" Italics: wrap your word in three asterisks Strike out: wrap your word in two tildes \"~\"","title":"Markdown Syntax"},{"location":"Music/","text":"Music In the spirit of removing proprietary items to the extent that my knowledge and ability allow, I deiced to switch to the old fashion mp3 player. I chose the Sony Walkman as it had the features I liked: Bluetooth Small in size Expandable Memory (256GB at the moment for my use) Simple Interface Comes with music library for Windows, but could also use simple drag and drop of files to transfer music wide array of file types supported Problem I had an old laptop that contained most of the music I've horded since middle school. I simply selected all the files and placed them in my SanDisk memory. About 730 of the files were corrupted, transferring over 0 bytes. Solution After sorting the files by size, I then created .opus files to form my play list. I realized that I had several dozen .opus files that my mp3 could not read. I had to batch convert. All over the web I found different types of answers all that were too complex. My friend attempted to help but I got a parse error, still need to debug this. But for now- to convert a directory of *.[m4a,opus,etc] files to another type of file using ffmpeg the following command works: for i in *.opus; do ffmpeg -i \"$i\" -b:a 192k \"$i%.*}.mp3\"; done The above command will take all .opus files and spit out individually named .mp3 files. Please do this in the directory where your files are Clean up I recommend doing a simple rm *.opus to remove all excess opus files post convert.","title":"Audio"},{"location":"Networking/","text":"Network Introduction A network is nothing two or more computers connected by a cable or a wireless radio connection so that they can exchange information. These computers are normally connected by a wire that's on a switch, the switch is normally connected to a patch panel in small and big businesses. Networks are designed to share files, resources and programs. LAN stands for local area network. WAN stands for wide area network. MAN stands for metropolitan area network. The network that contains the hard drives printers and other resources that are shared with network computers is a server . Any computer that is not a server is a client. A node is a device that's connected to the network. A node is the same as a computer. A packet is a message that is sent over the network from one node to another node. The packet includes the address of the node that sent the packet. Networking The internet protocol (IP) defines the format of IP addresses: four eight-bit numbers called octets who's decimal values rage from 0 to 255. Layers Definition Physical (1) mechanical & electrical details of network components, this includes cables, connectors and network interfaces. Data link (2) how devices are identified on the network, typically MAC addresses. Switches operate at this layer. Network (3) handles the routing of data across networks. Routers operate here. Transport (4) provides the reliable delivery of packets. Session (5) establishes sessions between network applications. Presentation (6) converts data so that systems that use different data formats can exchange information. Application (7) allows applications to request network services. a trick to remember this is the mnemonic is ***A***ll ***P***eople ***S***eem ***T***o ***N***eed ***D***ata ***P***rocessing","title":"Networking"},{"location":"Resources/","text":"Resources This will be a location for links of useful information I have found that has helped me with issues, questions or just curiosities. Websites I will include a quick scenario for which each link has helped me. W1 Backup Options https://www.howtogeek.com/427480/how-to-back-up-your-linux-system/ I had a corrupted motherboard. It could not hold the Windows OS (think blue screen of death). I scrapped that for Ubuntu, and it crashed about 8 times in the span of one month. It was the stable build. Now that I have a new machine, I want to not have to continue to download all the configurations I made. I was not able to perform it via rsync but I did use grsync. W2 Password Management I most often use KDBX file types for password storage such as Macpass for Mac OS & Keeweb for Linux/Windows OS. A shared/local & individual & within the terminal you can use: https://www.passwordstore.org/ The tutorial I used is: https://www.fossmint.com/pass-commandline-password-manager-for-linux/ ( also very glad to see it was a POC blogger )","title":"Resources"},{"location":"Securedrop/","text":"SecureDrop At my current role, I am a SecureDrop (SD) admin. It was not known to me how intense this role would be and all the terminal jargon I would have to know. Because of this, I will also store here and share tips and tricks that I have learned throughout my 3 years working with the tool. What is it? SecureDrop is an open source whistle blower submission system that media organizations and NGOs can install to securely accept documents from anonymous sources. It was originally created by the late Aaron Swartz and is now managed by Freedom of the Press Foundation. SecureDrop is available in 20 languages. More info can be found here . For my day-to-day I check SD for anonymous submissions of potential news story leads. How does it work? Tails I will be limiting this section for security reasons. SecureDrop works with the The Amnesic Incognito Live System (tails). It\u2019s an OS system, similar to Linux, MacOS & windows. The beauty of it is that it boots from a USB, and wipes itself clean after each use. It works only with TOR browsers. Arguably considered the most way to secure yourself on the internet. Check out more on tails here . Tails works in conjunction with tor browsers that use .onion websites. Info on tor here The Computers There is an Admin Station & there is a Secure Viewing Station (svs) . The admin station has access to the internet, where I use tor to access \".onion\" sites. I pull attachments from said sites, load them to an encrypted USB. This USB is then taken to the SVS. Both machines utilize tails exclusively. The SVS is not connected to the internet. With the encrypted USB drive and another tails USB, the system boots. From there the contents of submissions and such are able to be viewed. The backbone of security for viewing submissions relies on long pass-phrases & PGP, check out the PGP documentation in my git for more on that. Maintenance of SD Being a sysadmin for SD requires understanding of the command line, SSH with sever(s), and the role of each USB. FPF attempts to make it easy with GUI options but I can attest that this does not always work. Command line When updating and you don\u2019t see it working with the GUI V2 & V3 Upgrade Recently it was announced that the support for V2 onions would cease. Earlier I mentioned onion (tor browsers). Check back there in case you need a refresher. This leaves V2 running instances vulnerable, eliminate the vulnerability by switching to V3. Steps Verify ssh config files for Mon and App (your servers) Every secure drop instance will have the Admin USB and the Journalist USB, for any major configurations to SD, it will run from the admin USB only. First, open the terminal navigate to the SD directory- enter cd ~/Persistent/securedrop then verify that in servers (app & mon) have the files for ssh, they are titled app-ssh-ths & mon-ssh-ths . If they are there, excellent. If not, contact FPF support ASAP . Check your git status Within the same cd ~/Persistent/securedrop , enter git status . This will have the output of where the head detached at x.x.x . You want to make sure that its at the latest version. Verify what servers app & mon are connected to Again, within the same directory type this command cat ~/Persistent/securedrop/install_files/ansible-base/app-source-ths . After this command is run there is a secret URL that should be displayed here. When I say secret its a URL made of tons of letters- this is not to be shared. In my case there was not a secret URL it was a plain IP address not good. What to do? Reconfigure the servers. Run ssh -vvv app ssh -vvv mon . This will produce a verbose output of the debug as its attempting to connect with the servers. Note that this point for me nothing was really showing beyond it not connecting. After that you have to reconfigure your admin USB stick. To reconfigure type ./securedrop-admin sdconfig . As a reminder this is all within the ~Persistent/securedrop directory. The sdconfig gets all the configurations ready to send to the servers. It will provide with an interactive CL prompt where you will go through a series of questions. In this section, we also pay close attention to the questions on enabling or disabling V2, V3. Be sure to click yes for V3. Keeping V2 on is optional, but less secure. After that completes, you can type cat ~/.ssh/config . This will show the ssh configuration file, and we should see the private onion URL rather than the plain IP address we were seeing earlier. Test ssh Connection To test your ssh connection to the severs enter ssh app & ssh mon . If your terminal switches to app@XXXX then you've successfully SSH'd. Back up the admin stick It's good practice to create back ups of the admin stick/ journalist stick(s) in case something goes wrong during an upgrade you can always roll back. To do that enter ./securedrop-admin backup . This command creates a tarball for the current settings. This will take a while, do not fret. Pushing the Configurations to the Servers So everything that was done so far was only done locally within the tails/admin USB. The severs have no idea, and they are still operating under the old configurations. To make sure the servers have the correct configurations installed you should do the following. Run ./securedrop-admin sdconfig \u2190 applies the changes locally once more Run ./securedrop-admin install \u2190 this will send the configurations made in the step above to the servers. End I would ensure that you still have ssh capabilities. See above. And finally I would make sure that you have access to both of your instances. If you enabled V3, there should be a new link you should take note of which will appear as you access the source and journalists interface on the tor browser!","title":"Securedrop"},{"location":"Server%20Wifi%20Install/","text":"Server Relocation I found myself having to relocate. This means the current DHCP settings that I had in the router that I could control are going out the window. To break that down I was able to log into my parents router and assign myself a specific IP so that when I SSH into my server I do not have to worry about the IP address changing. What is SSH? SSH stands for secure shell or secure socket. Its a cryptographic network protocol that allows two computers to communicate and share data. When SSHing into a server the command syntax will typically follow this structure: ssh [username]@[IP Address or hostname] The default port for SSH is normally 22, because this is common knowledge for security reasons its better to change the open port to another number so that it restricts access. If you opt to change the port number there is an argument that you have to include within your command. ssh -p [port number] [username]@[IP Address or hostname] Finally, sshing to a port for the first time (or more) will ask you for a key, you can refer to my post rsa$config . If you need to specify a specific key the command will change to: ssh -p [port number] -i [path/to/key] [username]@IP Address or hostname] Sever VS Wifi The servers that I have worked with have always been either - connected via ethernet - cloud based (in which the service provider handles the connection) With my current living situation I could not connect an RJ45 from the router to my server :( so I had to do it via wifi. I will go through the steps that I took to get there. I asked around my network of folks and no one knew how to connect a server to Wifi. My first steps from some reading: - determine if my apple mini came with a NIC (network interface card). This would speak to the router in the house and get me connected - if it didn't, purchase a network adapter To check if my apple mini came with a NIC I ran ip a and this listed out a ton of jibberish on what my server had. I saw that it had an eth0 but nothing starting with a w which is what would indicate something relating to wifi.","title":"Adding Wifi to Local Server"},{"location":"VS%20Code%20Install/","text":"What is it? VS code is a free open-source code editor that is available for all major platforms. I was attempting to run Git in a more traditional fashion with the command line but I found it hard to find a spell checker for vim. IF you're reading this, please feel free to drop tips on how to do this, also taking a mental note to find my own solution. In the interim, I am using VS code downloaded here . What I have learned is that you can use VS code to write in several languages with a nice UX. There is a built in terminal & you can connect it to your GitHub. How to Connect GitHub<->VS Code Once downloaded, if you click the branch icon on the left panel it will ask if you want to clone, create, import a repository. If you click import, it will give you the option to paste the link to you git. Go into your repo, and paste the HTTPS URL. From there, a pop up will prompt you to connect your VSCODE to your GIT. Once you login on GIT, it will link. You should get a successful output. Note: there is other forms, I am sure- but this very straight forward. VSCode Spell-Right I have tested VSCODE spell-check, while very easy to install, (its plug and play-it) does not provide case sensitive feedback for your languages, in my case- markdown. So, I have used VS Spell-right . Installation was a bit complicated on Debian, but I sorted it out. Steps Going into the extensions option The steps on the VS spell-right git states that you have to Create the dictionaries sub folder as it doesn't exist by default. Here Here","title":"VS Code"},{"location":"Web%20Services/","text":"Why? Systems is very vast, creating a space to show the things learned over time will be helpful in a reference point to find things when stuck. Hope this helps. VPN If you ever have an issue with a connection one of the common places to check is your resolv.conf file. How? In your terminal with your editor of choice open resolv.conf, if you do not have this file the editor will automatically create it. You will want to add the namesever of the site you're trying to reach. Example: nameserver 172.X.XX.X.X When not needed feel free to comment it out. Example: #nameserver 172.X.XX.X.X The system wont read it. Once you have made this change, you will want to make sure that in your VPN client you go to the configuration settings and select something manual along the lines of \"allow changes manually to network changes\". ## External HardDrive When you have to move files, for example a tarball you need to execute the following command: tar -cvfz [NAME OF TARBALL].tar.gz [DESIRED LOCATION OF FILE] Connecting To Servers Working on systems will have you remoting into several machines. At times you will have to copy over tarballs from one machine into yours or your desired external storage device. For this you will use the scp command. In some cases your machine will not have a direct path to your key when you must list it out the command is as follows: scp -p 443 -i [PATH TO KEY] This command lists the port also to copy and where the key is to connect to the server. An example of copying contents from one server to an external hard drive would be: scp -p 443 -i ~/.ssh/[CERTIFICATE LOCATION] USERNAME@SEVERNAME:[LOCATION OF TARBALL][LOCATION WHERE YOU WANT IT COPIED] If you're lost on where to find the file path to your external drive (if thats where you want to push documents) Mac: Open the Disk Utility in the /Applications/Utilities/ folder, click on the partition, choose Info, and look at the disk identifier. Example: `Volumes/\"My Passport for Mac\" Linux: To be continued Windows: if you click on computer, then click the external drive in question, at the top of the window it will show you the path. Example: `C: Users\\sunflowerno0b\\USB Yes, this is very unique and its not commonly found, normally you indicate the scp command connect to the server and location of where you want to contents copied. 2FA Reset for OpenVPN VPNs allow for secure access to certain sites for your systems team. For example some teams may need only internal members to access your git. Authentication to these VPN protected sites normally include: ssl certificate username & password MFA When MFA needs to be rest, you should always look at the documentation. To rest the 2FA for a specific user using OpenVPN: ssh into the VPN (1XX.XX.XXX.XX) go into the root directory cd / run find / | grep sacli cd into the scripts folder run sudo ./scali -- user [USERNAME] --KEY \"prop_google_auth\" -- value \"false\" UserProPut Note that this will disable the google authenticator for the specific user. run sudo ./sacli -- user[USERNAME] -- lock 0 Google AuthLock this will reset the Google Authenticator for the user to rescan upon signing in again. Further options can be explored here VPN & LDAP When configuring VPN that will use your teams LDAP it is best practices for the username to match the LDAP profile when creating the user in admin. Should a user lose or replace phone","title":"Web Services"},{"location":"rsa%20%26%20config/","text":"RSA & CONFIG In systems administration much of the work performed requires the sysadmin to ssh into a machine. Organizations, if prudent will need the users RSA keys in order to provide secure authentication. RSA works under asymmetric encryption with the user generating a private & a public key pair. These keys are later stored in locations such as GitHub, gitea etc. Generating an RSA key Reading material here .ssh/ Config The .ssh directory includes files used for secure shell protocol. It's a cryptographic network protocol for operating network services securely over an unsecured network. There will be times where the systems team makes changes to the security infrastructure. Changes can include but are not limited to: changing HA Proxy rules updates to the bastion VPN updates IP address changes Potential Problem User at my org was attempting to ssh into a machine but was getting an UNREACHABLE! => {\"changed\"}: false, \"msg\": \"Failed to connect to the host via ssh: ssh: connect to host XXX.XX.X.XXX port 22: COnnection timed out\", \"unreachable\": true} Solution Thought Process First, I realized this user had been out for about two weeks, perhaps their key expired & needed updating. This was not the case; they key the user was using was the team key for a generic user, not specific. I had to attempt to recreate the issue (note my friend guided my hand through all this, always grateful for you\u2661). I asked user to attempt connecting but directing ssh to the user key with the following command: ssh -i ~/.ssh/KEYFILE User states that this did not work either. I next asked for user to print out the debug report with the command: ssh -vv -i ~/.ssh/KEYFILE The debug report stated that user was trying to connect with there ssh config but .*.conf matched no files User states that config file was up to date. But the systeam just made changes to the bastion within the time frame that the user was out. User pasted their config file. Here is where I compared it to my config file and noticed they were missing a line which included our internal IP Range for host, user, identity file for the proxyJump bastion . Once they added the file, it worked.","title":"RSA/config"}]}